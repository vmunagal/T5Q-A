{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwAMyTmU1IhA"
      },
      "outputs": [],
      "source": [
        "! pip install --quiet  transformers\n",
        "! pip install --quiet  sentencepiece\n",
        "! pip install --quiet  datasets\n",
        "! pip install --quiet  evaluate\n",
        "! pip install --quiet git+https://github.com/google-research/bleurt.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(f'transformers.__version__: {transformers.__version__}')"
      ],
      "metadata": {
        "id": "vIZCDYoF2T0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import gc \n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from transformers import AdamW,T5ForConditionalGeneration, T5TokenizerFast as T5Tokenizer , Adafactor\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.optim import Adam\n",
        "from transformers.optimization import Adafactor, AdafactorSchedule\n",
        "from torch.cuda import amp \n",
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import sys\n",
        "from tqdm.notebook import tqdm \n",
        "import os \n",
        "import warnings\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from transformers import get_cosine_schedule_with_warmup , get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split \n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "CJO0pprAur2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    train_lr = 1e-4\n",
        "    encoder_length = 512\n",
        "    decoder_length = 120\n",
        "    model='t5-base'\n",
        "    train_batch_size = 8\n",
        "    cv_batch_size = 16\n",
        "    epochs = 5\n",
        "    tokenizer= T5Tokenizer.from_pretrained(model)\n",
        "    clip=1.0"
      ],
      "metadata": {
        "id": "eCQ2lOnB8KhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sourec text \n",
        "source_df = pd.read_csv('/content/drive/MyDrive/ts_competition/source_texts.csv')\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/ts_competition/train.csv')"
      ],
      "metadata": {
        "id": "TmdiPq_M8zHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eassy text \n",
        "source_df.text.map(lambda x: len(x)).max()"
      ],
      "metadata": {
        "id": "VE7tCs2A-N6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_df[source_df['source_title']=='a-fish-story'] # yuletide-specters"
      ],
      "metadata": {
        "id": "nz4CC1Y-AGyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[train_df['source_title']=='yuletide-specters']['answer']"
      ],
      "metadata": {
        "id": "9EBsjygiAPA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_df[(source_df['source_title']==\"remarkable-rocket\") &  (source_df['cor_section']==5)]"
      ],
      "metadata": {
        "id": "Og92FRN-t6N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = []\n",
        "for idx , data in enumerate(train_df[['source_title','cor_section']].values):\n",
        "    try:\n",
        "        if len(data[1]) >= 2:\n",
        "            cor_section_concat=''\n",
        "\n",
        "            for x in data[1].split(','):\n",
        "                cor_section_concat=cor_section_concat+source_df[(source_df['source_title']==data[0]) & (source_df['cor_section']==int(x))].text.item()\n",
        "            text_list.append(cor_section_concat)\n",
        "        else:\n",
        "           \n",
        "            text_list.append(source_df[(source_df['source_title']==data[0]) & (source_df['cor_section']==int(data[1]))].text.item())\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(idx)\n",
        "        print(data)\n",
        "       \n",
        "\n",
        "                       "
      ],
      "metadata": {
        "id": "CAc_SOgZQm4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.iloc[2999]['question']"
      ],
      "metadata": {
        "id": "Bw0jyh_Ayguy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list.insert(2999,source_df.iloc[1150]['text'])"
      ],
      "metadata": {
        "id": "YuJsSpHozMVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.loc[:,'text']=text_list"
      ],
      "metadata": {
        "id": "Kg9kqvRtqOyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEP_TOKEN='*'"
      ],
      "metadata": {
        "id": "7nrfCwhfo-fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 0 \n",
        "for  question in train_df['question'].values:\n",
        "\n",
        "    output = CFG.tokenizer.encode(question)\n",
        "\n",
        "    if len(output) > max_length:\n",
        "        max_length = len(output)\n",
        "\n",
        "CFG.decoder_length = max_length  \n",
        "print(f'The Max length of the decoder : {CFG.decoder_length}') "
      ],
      "metadata": {
        "id": "uJGAWrlPsQJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset():\n",
        "    def __init__(self,text, question , answer):\n",
        "        self.text = text\n",
        "        self.question = question\n",
        "        self.answer=answer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text+self.question+self.answer)\n",
        "    \n",
        "    def __getitem__(self,item):\n",
        "        \n",
        "        text = self.text[item]\n",
        "\n",
        "        question = self.question[item]\n",
        "\n",
        "        answer = self.answer[item]\n",
        "\n",
        "        # Encoder tokens \n",
        "\n",
        "        encoder_tokens = CFG.tokenizer(SEP_TOKEN+answer+SEP_TOKEN,text,max_length = CFG.encoder_length,padding='max_length',truncation='only_second',add_special_tokens=True,return_attention_mask=True,return_tensors='pt')\n",
        "\n",
        "        input_ids, attention_mask = encoder_tokens.input_ids, encoder_tokens.attention_mask\n",
        "\n",
        "        decoder_toekns= CFG.tokenizer(question,max_length = CFG.decoder_length ,padding='max_length',add_special_tokens=True,return_attention_mask=True,return_tensors='pt')\n",
        "\n",
        "\n",
        "        labels = decoder_toekns.input_ids\n",
        "\n",
        "        labels[labels == CFG.tokenizer.pad_token_id] = -100\n",
        "\n",
        "\n",
        "        return {\n",
        "\n",
        "            'input_ids':input_ids.flatten(),\n",
        "            'attention_mask': attention_mask.flatten(),\n",
        "            'labels':labels.flatten()\n",
        "\n",
        "        }\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bM-fpmBZtTsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class T5QAModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(T5QAModel,self).__init__()\n",
        "        self.model=T5ForConditionalGeneration.from_pretrained(CFG.model,return_dict=True)\n",
        "    def forward(self,input_ids,attention_mask,labels=None):\n",
        "        output = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        \n",
        "        return output.loss , output.logits \n"
      ],
      "metadata": {
        "id": "t2WdhPGgzWDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "mAGwbY5A1xUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model=T5QAModel()"
      ],
      "metadata": {
        "id": "XXRWX8u312ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model.to(DEVICE)"
      ],
      "metadata": {
        "id": "T-4s5oiU16k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in Model.parameters() if p.requires_grad)\n",
        "print(f'The No.of trainable parameters : {total_params}')"
      ],
      "metadata": {
        "id": "_vyeyG-716a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "bleurt = load_metric(\"bleurt\", module_type=\"metric\")"
      ],
      "metadata": {
        "id": "2jskw9swLp5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def outputstring_cal(predicted_tokens):\n",
        "    if predicted_tokens.dim()==1:\n",
        "        output_tokens=[]\n",
        "        for token_ids in predicted_tokens:\n",
        "            data_list=[]\n",
        "            data_list.append(token_ids)\n",
        "            if int(token_ids)==1:\n",
        "                break\n",
        "            else:\n",
        "              output_tokens.append(CFG.tokenizer.decode(data_list))      \n",
        "        return ' '.join(output_tokens)       \n",
        "    elif predicted_tokens.dim()==2 :\n",
        "        return [outputstring_cal(predicted_tokens[i, :]) for i in range(predicted_tokens.size(0))]\n",
        "\n",
        "    raise RuntimeError(f' The dimesion should be 2 but we received {predicted_tokens.dim()} ')\n"
      ],
      "metadata": {
        "id": "GSC6uRapILCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(train_data,optimizer,scheduler=None): \n",
        "    Model.train()\n",
        "    total_loss=0\n",
        "\n",
        "    train = tqdm(train_data, total=len(train_data))\n",
        "    \n",
        "    for batch_size , data in enumerate(train):\n",
        "\n",
        "\n",
        "        input_ids=data['input_ids']\n",
        "        attention_mask = data['attention_mask']\n",
        "        labels = data['labels']\n",
        "\n",
        "        input_ids = input_ids.to(DEVICE)\n",
        "\n",
        "        attention_mask = attention_mask.to(DEVICE)\n",
        "\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "\n",
        "        loss,_=Model(input_ids,attention_mask,labels)\n",
        "\n",
        "        total_loss+=loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(Model.parameters(), CFG.clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        perplexity = np.exp(total_loss / len(train_data))\n",
        "        \n",
        "    return  perplexity"
      ],
      "metadata": {
        "id": "ahg46Z-H24xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "def eval_fn(val_data):\n",
        "    Model.eval()\n",
        "    total_loss=0\n",
        "\n",
        "    hypotheses=[]\n",
        "\n",
        "    actual = []\n",
        " \n",
        "    with torch.no_grad():\n",
        "        tk = tqdm(val_data, total=len(val_data)) \n",
        "        for batch_size , data in enumerate(tk):\n",
        "\n",
        "\n",
        "            input_ids=data['input_ids']\n",
        "            attention_mask = data['attention_mask']\n",
        "            labels = data['labels']\n",
        "\n",
        "            input_ids = input_ids.to(DEVICE)\n",
        "\n",
        "            attention_mask = attention_mask.to(DEVICE)\n",
        "\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            loss, logits =Model(input_ids,attention_mask,labels)\n",
        "\n",
        "          \n",
        "            total_loss+=loss.item()\n",
        "\n",
        "            output = logits.argmax(dim=-1)\n",
        "\n",
        "            predicited_string = outputstring_cal(output)\n",
        "\n",
        "          \n",
        "\n",
        "            actual_string= outputstring_cal(labels)\n",
        "\n",
        "            hypotheses.extend(predicited_string)\n",
        "\n",
        "            actual.extend(actual_string)\n",
        "\n",
        "          \n",
        "    perplexity = np.exp(total_loss / len(val_data))\n",
        "  \n",
        "    bleurt_metric = bleurt.compute(predictions=hypotheses, references=actual)\n",
        "\n",
        "    \n",
        "    return perplexity , np.mean(bleurt_metric['scores'],axis=0)"
      ],
      "metadata": {
        "id": "vcJqi-WoGREK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "def run():\n",
        "\n",
        "    df_train , df_valid= train_test_split(train_df,test_size=0.3, random_state=42)\n",
        "\n",
        "    df_train=df_train.reset_index(drop=True)\n",
        "    df_valid=df_valid.reset_index(drop=True)\n",
        "\n",
        "    train_data=QADataset(\n",
        "    text=df_train.text.values,\n",
        "    question=df_train.question.values,\n",
        "    answer=df_train.answer.values \n",
        "    \n",
        "    )\n",
        "\n",
        "    train_data_loader=torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=CFG.train_batch_size\n",
        "     )\n",
        "    \n",
        "    val_data_loader=QADataset(\n",
        "    text=df_valid.text.values,\n",
        "    question=df_valid.question.values,\n",
        "    answer=df_valid.answer.values \n",
        "    \n",
        "    )\n",
        "\n",
        "  \n",
        "    validation_data_loader=torch.utils.data.DataLoader(\n",
        "    val_data_loader,\n",
        "    batch_size=CFG.cv_batch_size\n",
        "    )\n",
        "\n",
        "    num_train_steps = int(len(train_data) /CFG.train_batch_size)* CFG.epochs\n",
        "\n",
        "    param_optimizer = list(Model.model.named_parameters())\n",
        "\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    \n",
        "    \n",
        "    optimized_paramater=[\n",
        "        \n",
        "            {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer  if not any(\n",
        "                nd in n for nd in no_decay\n",
        "            )\n",
        "        ],\n",
        "        \"weight_decay\": 0.01,\n",
        "    },    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer  if any(\n",
        "                nd in n for nd in no_decay\n",
        "            )\n",
        "        ],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },\n",
        "    ]\n",
        "\n",
        "    optimizer = Adam(optimized_paramater, lr=CFG.train_lr)\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps=100, \n",
        "        num_training_steps=num_train_steps\n",
        "    )\n",
        "\n",
        "    best_bleurt = float('-inf')\n",
        "    es_patience = 3\n",
        "    patience = 0 \n",
        "    model_path = f'/content/drive/MyDrive/T5Model/model-t5-small-new-{CFG.train_lr}.pth'\n",
        "\n",
        "    for i in range(CFG.epochs):\n",
        "\n",
        "\n",
        "        print(\"Epoch {}/{}\".format(i+1,CFG.epochs))\n",
        "\n",
        "        train_prexlity=train_fn(train_data_loader,optimizer,scheduler=scheduler)\n",
        "\n",
        "        test_prexlity , bleurt_metric = eval_fn( validation_data_loader)\n",
        "  \n",
        "        print(f'Epoch :{i+1} and  train prexlity {train_prexlity:.2f}')\n",
        "\n",
        "        print(f'Epoch :{i+1} and  test prexlity {test_prexlity:.2f} and bleurt_metric : {bleurt_metric:.2f}' )\n",
        "\n",
        "\n",
        "        is_best = bleurt_metric > best_bleurt \n",
        "        if is_best:\n",
        "            print(f'score improved ({best_bleurt:.4f} -> {bleurt_metric:.4f}). Saving Model!')\n",
        "            best_bleurt = bleurt_metric\n",
        "            patience = 0\n",
        "            torch.save(Model.state_dict(), model_path)\n",
        "        else:\n",
        "            patience += 1\n",
        "            print(f'Early stopping counter: {patience} out of {es_patience}')\n",
        "            if patience == es_patience:\n",
        "                print(f'Early stopping! Best score: {best_bleurt:.4f}')\n",
        "                break"
      ],
      "metadata": {
        "id": "1ziw3kyRHUF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Rs4O8M_Nu3pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "id": "-RcbBPniJL8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc \n",
        "del Model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "ZTeJT2hr1vpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model"
      ],
      "metadata": {
        "id": "QI1a9-voAylK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc \n",
        "del Model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "w7FKePC1Ml7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model = T5QAModel()\n",
        "Model.load_state_dict(torch.load(f'/content/drive/MyDrive/T5Model/model-t5-base-0.0001.pth',map_location=torch.device('cpu')))\n",
        "Model.to(DEVICE)\n",
        "Model.eval()"
      ],
      "metadata": {
        "id": "RwAJ4f3CA2nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predictedQA(Model,answer , text):\n",
        "    \n",
        "    \n",
        "    encoder_tokens = CFG.tokenizer(SEP_TOKEN+answer+SEP_TOKEN,text,max_length = CFG.encoder_length,padding='max_length',truncation='only_second',add_special_tokens=True,return_attention_mask=True,return_tensors='pt')\n",
        "\n",
        "    input_ids, attention_mask = encoder_tokens.input_ids, encoder_tokens.attention_mask\n",
        "\n",
        "\n",
        "    output_ids = Model.model.generate(\n",
        "        input_ids=input_ids.to(DEVICE),\n",
        "        attention_mask=attention_mask.to(DEVICE),\n",
        "        num_beams=1,\n",
        "        max_length=CFG.decoder_length,\n",
        "        repetition_penalty=2.5,\n",
        "        length_penalty=1.0,\n",
        "        use_cache=True\n",
        "    )\n",
        "\n",
        "\n",
        "    preds = {\n",
        "        CFG.tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "        for ids in output_ids\n",
        "    }\n",
        "\n",
        "    return ''.join(preds)"
      ],
      "metadata": {
        "id": "TbpwPoTkBa3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def result(generated , answer, context, original_question):\n",
        "    print('Generated: ', generated)\n",
        "    if original_question:\n",
        "        print('Original : ', original_question)\n",
        "\n",
        "    print()\n",
        "    print('Answer: ', answer)\n",
        "    print('Conext: ', context)\n",
        "    print('*'*100)"
      ],
      "metadata": {
        "id": "CG-phZn2C877"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_records=np.random.randint(1,6000,10)"
      ],
      "metadata": {
        "id": "qTbp2tGZDIen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in random_records:\n",
        "\n",
        "    print(f'The record number : {x}')\n",
        "\n",
        "    sample_question = train_df.iloc[x]\n",
        "\n",
        "    generated=predictedQA(Model, sample_question['answer'], sample_question['text'])\n",
        "\n",
        "    result(generated, sample_question['answer'], sample_question['text'], sample_question['question'])"
      ],
      "metadata": {
        "id": "47IgMGRs9EWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "predicited=[]\n",
        "actual =[]\n",
        "for x in train_df.index:\n",
        "    generated=predictedQA(Model, train_df['answer'][x], train_df['text'][x])\n",
        "    predicited.append(generated)\n",
        "    actual.append(train_df['question'][x])\n",
        "    count+=1\n",
        "    if count==100:\n",
        "        break\n",
        "        print(\"Break encountred\")"
      ],
      "metadata": {
        "id": "E8Jov2A2G_LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import string\n",
        "import re\n",
        "\n",
        "# BLEURT functions\n",
        "def normalize(text):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(text))))\n",
        "\n",
        "def grade_score(df):\n",
        "    nls = []\n",
        "    for curit, (q, gq) in enumerate(zip(df['reference_question'], df['generated_question'])):\n",
        "        if curit == 100:\n",
        "            break\n",
        "        else:\n",
        "            result = bleurt.compute(predictions=[normalize(q)], references=[normalize(gq)])\n",
        "            nls.append(result)\n",
        "    return nls\n",
        "\n",
        "bleurt = evaluate.load('bleurt', 'bleurt-20')"
      ],
      "metadata": {
        "id": "Vx7WRPPyfaKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(list(zip(predicited,actual)),columns=['generated_question','reference_question'])"
      ],
      "metadata": {
        "id": "NXISfw-0gWwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = grade_score(df)"
      ],
      "metadata": {
        "id": "8SWVfJFeg9al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score= np.mean([x['scores'][0] for x in output],axis=0)\n",
        "print(f'The Bluert score for the 100 data points : {score:.2f}')"
      ],
      "metadata": {
        "id": "cogWrU7Yi8Ts"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}