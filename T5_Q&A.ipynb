{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bac58b38cff94407a6cfdd20c6f6f33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efadc6a1174a4d2b9d5a84e14613b7e4",
              "IPY_MODEL_205889d9902a4a389e9837810b20bb1d",
              "IPY_MODEL_b00fbff42a084e6ba8a8c448c518a66c"
            ],
            "layout": "IPY_MODEL_71f0ba6e94064118bec218603af5d44b"
          }
        },
        "efadc6a1174a4d2b9d5a84e14613b7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2932f178c3d144ccae910cb0103887eb",
            "placeholder": "​",
            "style": "IPY_MODEL_d09e597c05b9412081f2584922c4fece",
            "value": "Downloading: 100%"
          }
        },
        "205889d9902a4a389e9837810b20bb1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a284c9b044c43b5b06db79fef24d267",
            "max": 891691430,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e7c2c7985804052858f1293c63593fc",
            "value": 891691430
          }
        },
        "b00fbff42a084e6ba8a8c448c518a66c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b35557c1609642bc9d89ca5ee865c241",
            "placeholder": "​",
            "style": "IPY_MODEL_1bfb50f26d3f47e8853d2f89487b164c",
            "value": " 892M/892M [00:40&lt;00:00, 35.7MB/s]"
          }
        },
        "71f0ba6e94064118bec218603af5d44b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2932f178c3d144ccae910cb0103887eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d09e597c05b9412081f2584922c4fece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a284c9b044c43b5b06db79fef24d267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e7c2c7985804052858f1293c63593fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b35557c1609642bc9d89ca5ee865c241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bfb50f26d3f47e8853d2f89487b164c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5dffdece28b47149e34c7386a056a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62b1af498dc44ed0bd20e6567bd8fd15",
              "IPY_MODEL_8a5d068346464dcd971f0f8335699415",
              "IPY_MODEL_398a578558324c4aa43eabed1e342237"
            ],
            "layout": "IPY_MODEL_560e8c555e804c36ac697fba0a61bb95"
          }
        },
        "62b1af498dc44ed0bd20e6567bd8fd15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46647dede7fc4f24a90c8ad4dc3c9610",
            "placeholder": "​",
            "style": "IPY_MODEL_dd862f483cd949c1bf5d2162b44b056f",
            "value": "Downloading builder script: 100%"
          }
        },
        "8a5d068346464dcd971f0f8335699415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e43df2a0f89c4e96bc5a86c75da2018f",
            "max": 5195,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a32e2caf627b4406ab899911cc994eff",
            "value": 5195
          }
        },
        "398a578558324c4aa43eabed1e342237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83b9408a0f924a1f8ac4dbdf3a0c6e10",
            "placeholder": "​",
            "style": "IPY_MODEL_4fc828561c7348a2981fc59e05c2fdac",
            "value": " 5.20k/5.20k [00:00&lt;00:00, 79.8kB/s]"
          }
        },
        "560e8c555e804c36ac697fba0a61bb95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46647dede7fc4f24a90c8ad4dc3c9610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd862f483cd949c1bf5d2162b44b056f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e43df2a0f89c4e96bc5a86c75da2018f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a32e2caf627b4406ab899911cc994eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83b9408a0f924a1f8ac4dbdf3a0c6e10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fc828561c7348a2981fc59e05c2fdac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "169004dcc4b047eeb24857a1765d3ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00c74d5fb3314bcfaa8db57f88103317",
              "IPY_MODEL_e71653c2fcc34707a14b3ebf54032e24",
              "IPY_MODEL_d9c616afab084163b9809eecd3ab3701"
            ],
            "layout": "IPY_MODEL_1d8f9c63bf4245838eaa036613bfd08a"
          }
        },
        "00c74d5fb3314bcfaa8db57f88103317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59815e2d6f254f2fa2086e16a187eb8c",
            "placeholder": "​",
            "style": "IPY_MODEL_0d67063812f045d4a8a77bf6ce6bb77b",
            "value": "Downloading data: 100%"
          }
        },
        "e71653c2fcc34707a14b3ebf54032e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac8f7552c9d44ad68f598e33097919e5",
            "max": 2140294207,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fab2d30a6f3645639f6a9d815fc2a0c9",
            "value": 2140294207
          }
        },
        "d9c616afab084163b9809eecd3ab3701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb031d00057d4964a036519299f52a64",
            "placeholder": "​",
            "style": "IPY_MODEL_d9f38c002e034abbbbd69593b23a51b9",
            "value": " 2.14G/2.14G [01:14&lt;00:00, 23.5MB/s]"
          }
        },
        "1d8f9c63bf4245838eaa036613bfd08a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59815e2d6f254f2fa2086e16a187eb8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d67063812f045d4a8a77bf6ce6bb77b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac8f7552c9d44ad68f598e33097919e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fab2d30a6f3645639f6a9d815fc2a0c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb031d00057d4964a036519299f52a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9f38c002e034abbbbd69593b23a51b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwAMyTmU1IhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd2a690-1e3d-4d9f-de75-b1ea549ab66a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.5 MB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 39.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 51.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 451 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 49.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 48.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 56.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 4.2 MB/s \n",
            "\u001b[?25h  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install --quiet  transformers\n",
        "! pip install --quiet  sentencepiece\n",
        "! pip install --quiet  datasets\n",
        "! pip install --quiet  evaluate\n",
        "! pip install --quiet git+https://github.com/google-research/bleurt.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(f'transformers.__version__: {transformers.__version__}')"
      ],
      "metadata": {
        "id": "vIZCDYoF2T0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786cd09c-6235-47c9-f727-d11f5b4de7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers.__version__: 4.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import gc \n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from transformers import AdamW,T5ForConditionalGeneration, T5TokenizerFast as T5Tokenizer , Adafactor\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.optim import Adam\n",
        "from transformers.optimization import Adafactor, AdafactorSchedule\n",
        "from torch.cuda import amp \n",
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import sys\n",
        "import random\n",
        "from tqdm.notebook import tqdm \n",
        "import os \n",
        "import warnings\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from transformers import get_cosine_schedule_with_warmup , get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split \n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "CJO0pprAur2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    train_lr = 1e-4\n",
        "    encoder_length = 512\n",
        "    decoder_length = 120\n",
        "    model='t5-base'\n",
        "    train_batch_size = 8\n",
        "    cv_batch_size = 16\n",
        "    epochs = 5\n",
        "    tokenizer= T5Tokenizer.from_pretrained(model)\n",
        "    clip=1.0\n",
        "    seed=42"
      ],
      "metadata": {
        "id": "eCQ2lOnB8KhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(CFG.seed)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(CFG.seed)\n",
        "np.random.seed(CFG.seed)\n",
        "torch.manual_seed(CFG.seed)\n",
        "torch.cuda.manual_seed(CFG.seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n"
      ],
      "metadata": {
        "id": "lbWfaOQSBVOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sourec text \n",
        "source_df = pd.read_csv('/content/drive/MyDrive/ts_competition/source_texts.csv')\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/ts_competition/train.csv')"
      ],
      "metadata": {
        "id": "TmdiPq_M8zHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eassy text \n",
        "source_df.text.map(lambda x: len(x)).max()"
      ],
      "metadata": {
        "id": "VE7tCs2A-N6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d10bbac-a6ac-4309-e2e8-07302582a6af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2193"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_df[source_df['source_title']=='a-fish-story'] # yuletide-specters"
      ],
      "metadata": {
        "id": "nz4CC1Y-AGyA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "832f9f01-a317-4d77-dfc1-e6592648e24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   source_title  cor_section  \\\n",
              "0  a-fish-story            1   \n",
              "1  a-fish-story            2   \n",
              "2  a-fish-story            3   \n",
              "3  a-fish-story            4   \n",
              "\n",
              "                                                text  \n",
              "0  Perhaps you think that fishes were always fish...  \n",
              "1  One day the whole fish tribe came back very ti...  \n",
              "2  'Let me try,' cried Biernuga, the bony fish, b...  \n",
              "3  'More wood,' cried Guddhi, and they all ran an...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca3010fc-2fbf-4814-a632-6338bd755ff9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_title</th>\n",
              "      <th>cor_section</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a-fish-story</td>\n",
              "      <td>1</td>\n",
              "      <td>Perhaps you think that fishes were always fish...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a-fish-story</td>\n",
              "      <td>2</td>\n",
              "      <td>One day the whole fish tribe came back very ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a-fish-story</td>\n",
              "      <td>3</td>\n",
              "      <td>'Let me try,' cried Biernuga, the bony fish, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a-fish-story</td>\n",
              "      <td>4</td>\n",
              "      <td>'More wood,' cried Guddhi, and they all ran an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca3010fc-2fbf-4814-a632-6338bd755ff9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca3010fc-2fbf-4814-a632-6338bd755ff9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca3010fc-2fbf-4814-a632-6338bd755ff9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[train_df['source_title']=='yuletide-specters']['answer']"
      ],
      "metadata": {
        "id": "9EBsjygiAPA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78683a3b-53b2-4c37-dd1b-166314fd8446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6974                                         two peasants\n",
              "6975             They would ride to Christmas night mass.\n",
              "6976    In those days, there was no such thing as a wa...\n",
              "6977    took a piece of bread from the table along wit...\n",
              "6978      She might be able to ride with the other woman.\n",
              "6979                                             a bridge\n",
              "6980                                     two witch trolls\n",
              "6981    She had a bit of bread in the form of a cross ...\n",
              "6982              She reached the church at Hanger alone.\n",
              "6983                                  She was in a hurry.\n",
              "6984                                            surprised\n",
              "6985                                     ran out hastily.\n",
              "6986    a broad mantle of unbleached wool, woven at ho...\n",
              "6987                         They had disturbed the dead.\n",
              "6988    some of the earth from the graves of those who...\n",
              "Name: answer, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_df[(source_df['source_title']==\"remarkable-rocket\") &  (source_df['cor_section']==5)]"
      ],
      "metadata": {
        "id": "Og92FRN-t6N2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "bd30d80c-14d6-4e11-9f11-c7b9fa7d3105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           source_title  cor_section  \\\n",
              "1150  remarkable-rocket            5   \n",
              "1151  remarkable-rocket            5   \n",
              "\n",
              "                                                   text  \n",
              "1150  What are fireworks like?\" she had asked the Pr...  \n",
              "1151  \"The world is certainly very beautiful,\" cried...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17f281cb-4e14-4742-bd7f-4c22d55c96fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_title</th>\n",
              "      <th>cor_section</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1150</th>\n",
              "      <td>remarkable-rocket</td>\n",
              "      <td>5</td>\n",
              "      <td>What are fireworks like?\" she had asked the Pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1151</th>\n",
              "      <td>remarkable-rocket</td>\n",
              "      <td>5</td>\n",
              "      <td>\"The world is certainly very beautiful,\" cried...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17f281cb-4e14-4742-bd7f-4c22d55c96fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17f281cb-4e14-4742-bd7f-4c22d55c96fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17f281cb-4e14-4742-bd7f-4c22d55c96fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = []\n",
        "for idx , data in enumerate(train_df[['source_title','cor_section']].values):\n",
        "    try:\n",
        "        if len(data[1]) >= 2:\n",
        "            cor_section_concat=''\n",
        "\n",
        "            for x in data[1].split(','):\n",
        "                cor_section_concat=cor_section_concat+source_df[(source_df['source_title']==data[0]) & (source_df['cor_section']==int(x))].text.item()\n",
        "            text_list.append(cor_section_concat)\n",
        "        else:\n",
        "            text_list.append(source_df[(source_df['source_title']==data[0]) & (source_df['cor_section']==int(data[1]))].text.item())\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(idx)\n",
        "        print(data)\n",
        "       \n",
        "\n",
        "                       "
      ],
      "metadata": {
        "id": "CAc_SOgZQm4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee7933e-0264-4313-9c8e-67b75e054b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "can only convert an array of size 1 to a Python scalar\n",
            "2999\n",
            "['remarkable-rocket' '5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.iloc[2999]['question']"
      ],
      "metadata": {
        "id": "Bw0jyh_Ayguy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "27687d6e-04cc-45df-c6d4-60d44962fbbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What did the fireworks do after the Royal Pyrotechnist had put everything in its proper place?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_list.insert(2999,source_df.iloc[1150]['text'])"
      ],
      "metadata": {
        "id": "YuJsSpHozMVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.loc[:,'text']=text_list"
      ],
      "metadata": {
        "id": "Kg9kqvRtqOyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEP_TOKEN='*'"
      ],
      "metadata": {
        "id": "7nrfCwhfo-fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 0 \n",
        "for  question in train_df['question'].values:\n",
        "\n",
        "    output = CFG.tokenizer.encode(question)\n",
        "\n",
        "    if len(output) > max_length:\n",
        "        max_length = len(output)\n",
        "\n",
        "CFG.decoder_length = max_length  \n",
        "print(f'The Max length of the decoder : {CFG.decoder_length}') "
      ],
      "metadata": {
        "id": "uJGAWrlPsQJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "319a3ba5-94f1-40d2-f207-72e873d9d0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Max length of the decoder : 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset():\n",
        "    def __init__(self,text, question , answer):\n",
        "        self.text = text\n",
        "        self.question = question\n",
        "        self.answer=answer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text+self.question+self.answer)\n",
        "    \n",
        "    def __getitem__(self,item):\n",
        "        \n",
        "        text = self.text[item]\n",
        "\n",
        "        question = self.question[item]\n",
        "\n",
        "        answer = self.answer[item]\n",
        "\n",
        "        # Encoder tokens \n",
        "\n",
        "        encoder_tokens = CFG.tokenizer(SEP_TOKEN+answer+SEP_TOKEN,text,max_length = CFG.encoder_length,padding='max_length',truncation='only_second',add_special_tokens=True,return_attention_mask=True,return_tensors='pt')\n",
        "\n",
        "        input_ids, attention_mask = encoder_tokens.input_ids, encoder_tokens.attention_mask\n",
        "\n",
        "        decoder_toekns= CFG.tokenizer(question,max_length = CFG.decoder_length ,padding='max_length',add_special_tokens=True,return_attention_mask=True,return_tensors='pt')\n",
        "\n",
        "\n",
        "        labels = decoder_toekns.input_ids\n",
        "\n",
        "        labels[labels == CFG.tokenizer.pad_token_id] = -100\n",
        "\n",
        "\n",
        "        return {\n",
        "\n",
        "            'input_ids':input_ids.flatten(),\n",
        "            'attention_mask': attention_mask.flatten(),\n",
        "            'labels':labels.flatten()\n",
        "\n",
        "        }\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bM-fpmBZtTsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class T5QAModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(T5QAModel,self).__init__()\n",
        "        self.model=T5ForConditionalGeneration.from_pretrained(CFG.model,return_dict=True)\n",
        "    def forward(self,input_ids,attention_mask,labels=None):\n",
        "        output = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        \n",
        "        return output.loss , output.logits \n"
      ],
      "metadata": {
        "id": "t2WdhPGgzWDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "mAGwbY5A1xUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model=T5QAModel()"
      ],
      "metadata": {
        "id": "XXRWX8u312ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model.to(DEVICE)"
      ],
      "metadata": {
        "id": "T-4s5oiU16k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in Model.parameters() if p.requires_grad)\n",
        "print(f'The No.of trainable parameters : {total_params}')"
      ],
      "metadata": {
        "id": "_vyeyG-716a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate \n",
        "\n",
        "bleurt = evaluate.load('bleurt', 'bleurt-20')"
      ],
      "metadata": {
        "id": "2jskw9swLp5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def outputstring_cal(predicted_tokens):\n",
        "    if predicted_tokens.dim()==1:\n",
        "        output_tokens=[]\n",
        "        for token_ids in predicted_tokens:\n",
        "            data_list=[]\n",
        "            data_list.append(token_ids)\n",
        "            if int(token_ids)==1:\n",
        "                break\n",
        "            else:\n",
        "              output_tokens.append(CFG.tokenizer.decode(data_list))      \n",
        "        return ' '.join(output_tokens)       \n",
        "    elif predicted_tokens.dim()==2 :\n",
        "        return [outputstring_cal(predicted_tokens[i, :]) for i in range(predicted_tokens.size(0))]\n",
        "\n",
        "    raise RuntimeError(f' The dimesion should be 2 but we received {predicted_tokens.dim()} ')\n"
      ],
      "metadata": {
        "id": "GSC6uRapILCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(train_data,optimizer,scheduler=None): \n",
        "    Model.train()\n",
        "    total_loss=0\n",
        "\n",
        "    train = tqdm(train_data, total=len(train_data))\n",
        "    \n",
        "    for batch_size , data in enumerate(train):\n",
        "\n",
        "\n",
        "        input_ids=data['input_ids']\n",
        "        attention_mask = data['attention_mask']\n",
        "        labels = data['labels']\n",
        "\n",
        "        input_ids = input_ids.to(DEVICE)\n",
        "\n",
        "        attention_mask = attention_mask.to(DEVICE)\n",
        "\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "\n",
        "        loss,_=Model(input_ids,attention_mask,labels)\n",
        "\n",
        "        total_loss+=loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(Model.parameters(), CFG.clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        perplexity = np.exp(np.mean(loss))\n",
        "        \n",
        "    return  perplexity"
      ],
      "metadata": {
        "id": "ahg46Z-H24xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "def eval_fn(val_data):\n",
        "    Model.eval()\n",
        "    total_loss=0\n",
        "\n",
        "    hypotheses=[]\n",
        "\n",
        "    actual = []\n",
        " \n",
        "    with torch.no_grad():\n",
        "        tk = tqdm(val_data, total=len(val_data)) \n",
        "        for batch_size , data in enumerate(tk):\n",
        "\n",
        "\n",
        "            input_ids=data['input_ids']\n",
        "            attention_mask = data['attention_mask']\n",
        "            labels = data['labels']\n",
        "\n",
        "            input_ids = input_ids.to(DEVICE)\n",
        "\n",
        "            attention_mask = attention_mask.to(DEVICE)\n",
        "\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            loss, logits =Model(input_ids,attention_mask,labels)\n",
        "\n",
        "          \n",
        "            total_loss+=loss.item()\n",
        "\n",
        "            output = logits.argmax(dim=-1)\n",
        "\n",
        "            predicited_string = outputstring_cal(output)\n",
        "\n",
        "          \n",
        "\n",
        "            actual_string= outputstring_cal(labels)\n",
        "\n",
        "            hypotheses.extend(predicited_string)\n",
        "\n",
        "            actual.extend(actual_string)\n",
        "\n",
        "          \n",
        "    perplexity = np.exp(np.mean(loss))\n",
        "  \n",
        "    bleurt_metric = bleurt.compute(predictions=hypotheses, references=actual)\n",
        "\n",
        "    \n",
        "    return perplexity , np.mean(bleurt_metric['scores'],axis=0)"
      ],
      "metadata": {
        "id": "vcJqi-WoGREK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "def run():\n",
        "\n",
        "    df_train , df_valid= train_test_split(train_df,test_size=0.3, random_state=42)\n",
        "\n",
        "    df_train=df_train.reset_index(drop=True)\n",
        "    df_valid=df_valid.reset_index(drop=True)\n",
        "\n",
        "    train_data=QADataset(\n",
        "    text=df_train.text.values,\n",
        "    question=df_train.question.values,\n",
        "    answer=df_train.answer.values \n",
        "    \n",
        "    )\n",
        "\n",
        "    train_data_loader=torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=CFG.train_batch_size\n",
        "     )\n",
        "    \n",
        "    val_data_loader=QADataset(\n",
        "    text=df_valid.text.values,\n",
        "    question=df_valid.question.values,\n",
        "    answer=df_valid.answer.values \n",
        "    \n",
        "    )\n",
        "\n",
        "  \n",
        "    validation_data_loader=torch.utils.data.DataLoader(\n",
        "    val_data_loader,\n",
        "    batch_size=CFG.cv_batch_size\n",
        "    )\n",
        "\n",
        "    num_train_steps = int(len(train_data) /CFG.train_batch_size)* CFG.epochs\n",
        "\n",
        "    param_optimizer = list(Model.model.named_parameters())\n",
        "\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    \n",
        "    \n",
        "    optimized_paramater=[\n",
        "        \n",
        "            {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer  if not any(\n",
        "                nd in n for nd in no_decay\n",
        "            )\n",
        "        ],\n",
        "        \"weight_decay\": 0.01,\n",
        "    },    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer  if any(\n",
        "                nd in n for nd in no_decay\n",
        "            )\n",
        "        ],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },\n",
        "    ]\n",
        "\n",
        "    optimizer = Adam(optimized_paramater, lr=CFG.train_lr)\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps=100, \n",
        "        num_training_steps=num_train_steps\n",
        "    )\n",
        "\n",
        "    best_bleurt = float('-inf')\n",
        "    es_patience = 3\n",
        "    patience = 0 \n",
        "    model_path = f'/content/drive/MyDrive/T5Model/model-t5-base-{CFG.train_lr}.pth'\n",
        "\n",
        "    for i in range(CFG.epochs):\n",
        "\n",
        "\n",
        "        print(\"Epoch {}/{}\".format(i+1,CFG.epochs))\n",
        "\n",
        "        train_prexlity=train_fn(train_data_loader,optimizer,scheduler=scheduler)\n",
        "\n",
        "        test_prexlity , bleurt_metric = eval_fn( validation_data_loader)\n",
        "  \n",
        "        print(f'Epoch :{i+1} and  train prexlity {train_prexlity:.2f}')\n",
        "\n",
        "        print(f'Epoch :{i+1} and  test prexlity {test_prexlity:.2f} and bleurt_metric : {bleurt_metric:.2f}' )\n",
        "\n",
        "\n",
        "        is_best = bleurt_metric > best_bleurt \n",
        "        if is_best:\n",
        "            print(f'score improved ({best_bleurt:.4f} -> {bleurt_metric:.4f}). Saving Model!')\n",
        "            best_bleurt = bleurt_metric\n",
        "            patience = 0\n",
        "            torch.save(Model.state_dict(), model_path)\n",
        "        else:\n",
        "            patience += 1\n",
        "            print(f'Early stopping counter: {patience} out of {es_patience}')\n",
        "            if patience == es_patience:\n",
        "                print(f'Early stopping! Best score: {best_bleurt:.4f}')\n",
        "                break"
      ],
      "metadata": {
        "id": "1ziw3kyRHUF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Rs4O8M_Nu3pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "id": "-RcbBPniJL8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc \n",
        "del Model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "ZTeJT2hr1vpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model"
      ],
      "metadata": {
        "id": "QI1a9-voAylK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc \n",
        "del Model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "w7FKePC1Ml7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model = T5QAModel()\n",
        "Model.load_state_dict(torch.load(f'/content/drive/MyDrive/T5Model/model-t5-base-0.0001.pth',map_location=torch.device('cpu')))\n",
        "Model.to(DEVICE)\n",
        "Model.eval()"
      ],
      "metadata": {
        "id": "RwAJ4f3CA2nt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bac58b38cff94407a6cfdd20c6f6f33f",
            "efadc6a1174a4d2b9d5a84e14613b7e4",
            "205889d9902a4a389e9837810b20bb1d",
            "b00fbff42a084e6ba8a8c448c518a66c",
            "71f0ba6e94064118bec218603af5d44b",
            "2932f178c3d144ccae910cb0103887eb",
            "d09e597c05b9412081f2584922c4fece",
            "8a284c9b044c43b5b06db79fef24d267",
            "7e7c2c7985804052858f1293c63593fc",
            "b35557c1609642bc9d89ca5ee865c241",
            "1bfb50f26d3f47e8853d2f89487b164c"
          ]
        },
        "outputId": "daf319d1-fd34-445f-ec16-745162d8c7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bac58b38cff94407a6cfdd20c6f6f33f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5QAModel(\n",
              "  (model): T5ForConditionalGeneration(\n",
              "    (shared): Embedding(32128, 768)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 768)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 12)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (4): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (7): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (8): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (9): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (10): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (11): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 768)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 12)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (4): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (7): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (8): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (9): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (10): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (11): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predictedQA(Model,answer , text):\n",
        "    \n",
        "    \n",
        "    encoder_tokens = CFG.tokenizer(SEP_TOKEN+answer+SEP_TOKEN,text,max_length = CFG.encoder_length,padding='max_length',truncation='only_second',add_special_tokens=True,return_attention_mask=True,return_tensors='pt')\n",
        "\n",
        "    input_ids, attention_mask = encoder_tokens.input_ids, encoder_tokens.attention_mask\n",
        "\n",
        "\n",
        "    output_ids = Model.model.generate(\n",
        "        input_ids=input_ids.to(DEVICE),\n",
        "        attention_mask=attention_mask.to(DEVICE),\n",
        "        num_beams=2, # Beam search will always find an output sequence with higher probability than greedy search, but is not guaranteed to find the most likely output.\n",
        "        max_length=CFG.decoder_length,\n",
        "        repetition_penalty=2.5,\n",
        "        length_penalty=1.0,\n",
        "        use_cache=True\n",
        "    )\n",
        "\n",
        "\n",
        "    preds = {\n",
        "        CFG.tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "        for ids in output_ids\n",
        "    }\n",
        "\n",
        "    return ''.join(preds)"
      ],
      "metadata": {
        "id": "TbpwPoTkBa3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def result(generated , answer, context, original_question):\n",
        "    print('Generated: ', generated)\n",
        "    if original_question:\n",
        "        print('Original : ', original_question)\n",
        "\n",
        "    print()\n",
        "    print('Answer: ', answer)\n",
        "    print('Conext: ', context)\n",
        "    print('*'*100)"
      ],
      "metadata": {
        "id": "CG-phZn2C877"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_records=np.random.randint(1,6000,10)"
      ],
      "metadata": {
        "id": "qTbp2tGZDIen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in random_records:\n",
        "\n",
        "    print(f'The record number : {x}')\n",
        "\n",
        "    sample_question = train_df.iloc[x]\n",
        "\n",
        "    generated=predictedQA(Model, sample_question['answer'], sample_question['text'])\n",
        "\n",
        "    result(generated, sample_question['answer'], sample_question['text'], sample_question['question'])"
      ],
      "metadata": {
        "id": "47IgMGRs9EWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd57c9d2-4927-48c4-a2ac-0f41ba435b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The record number : 5312\n",
            "Generated:  What did the brother's wife say when she tasted the pumpkin?\n",
            "Original :  Why did the brother's wife want to eat more pumpkins?\n",
            "\n",
            "Answer:  It was the nicest she had ever eaten.\n",
            "Conext:  Unluckily someone else thought so too, and this was her brother's wife,\n",
            "who had heard all about the pumpkin tree, and sent her slave with a\n",
            "handful of grain to buy her a pumpkin. At first the girl told him that\n",
            "so few were left that she could not spare any; but when she found that\n",
            "he belonged to her brother, she changed her mind, and went out to the\n",
            "tree and gathered the largest and the ripest that was there.\n",
            "\n",
            "'Take this one,' she said to the slave, 'and carry it back to your\n",
            "mistress, but tell her to keep the corn, as the pumpkin is a gift.'\n",
            "\n",
            "The brother's wife was overjoyed at the sight of the fruit, and when she\n",
            "tasted it, she declared it was the nicest she had ever eaten. Indeed,\n",
            "all night she thought of nothing else, and early in the morning she\n",
            "called another slave (for she was a rich woman) and bade him go and ask\n",
            "for another pumpkin. But the girl, who had just been out to look at her\n",
            "tree, told him that they were all eaten, so he went back empty-handed to\n",
            "his mistress.\n",
            "****************************************************************************************************\n",
            "The record number : 5052\n",
            "Generated:  Why were the ladies starving?\n",
            "Original :  Why were the ladies starving?\n",
            "\n",
            "Answer:  because the refused to eat the flesh of their won dead husbands\n",
            "Conext:  Jack next took a great bunch of keys from the pocket of Blunderbore,\n",
            "and went into the castle again. He made a strict search through all\n",
            "the rooms, and in one of them found three ladies tied up by the hair\n",
            "of their heads, and almost starved to death. They told him that their\n",
            "husbands had been killed by the giants, who had then condemned them to\n",
            "be starved to death because they would not eat the flesh of their own\n",
            "dead husbands.\n",
            "\n",
            "\"Ladies,\" said Jack, \"I have put an end to the monster and his wicked\n",
            "brother; and I give you this castle and all the riches it contains, to\n",
            "make some amends for the dreadful pains you have felt.\" He then very\n",
            "politely gave them the keys of the castle, and went further on his\n",
            "journey to Wales.\n",
            "****************************************************************************************************\n",
            "The record number : 1185\n",
            "Generated:  How did the Prince plan to help the poor?\n",
            "Original :  How did the Happy Prince plan to help the poor?\n",
            "\n",
            "Answer:  He told the swallow to give his gold feathers to the poor.\n",
            "\"I am covered with fine gold,\" said the Prince, \"you must take it off, leaf by leaf, and give it to my poor; the living always think that gold can make them happy.\"\n",
            "****************************************************************************************************\n",
            "The record number : 4556\n",
            "Generated:  How did Earl St. Clair feel after he saw the horseman?\n",
            "Original :  How did Earl St. Clair feel after his companion left him?\n",
            "\n",
            "Answer:  concerned\n",
            "Conext:  For some hours all went well; and in the heat of the chase the young men\n",
            "forgot their fears. Then suddenly both of them reined in their steeds\n",
            "and sat gazing in front of them with affrighted faces.\n",
            "\n",
            "For a horseman had crossed their track, and they both would fain have\n",
            "known who he was and whence he came.\n",
            "\n",
            "\"By my troth, but he rideth in haste, whoever he may be,\" said Earl\n",
            "Gregory at last, \"and though I always thought that no steed on earth could\n",
            "match mine for swiftness, I reckon that for every league that mine\n",
            "goeth, his would go seven. Let us follow him, and see from what part of\n",
            "the world he cometh.\"\n",
            "\n",
            "\"The Lord forbid that thou shouldst stir thy horse's feet to follow\n",
            "him,\" said Earl St. Clair devoutly. \"Why, man, it is the Elfin Knight!\n",
            "Canst thou not see that he doth not ride on the solid ground, but flieth\n",
            "through the air, and that, although he rideth on what seemeth a mortal\n",
            "steed, he is really craried by mighty pinions, which cleave the air like\n",
            "those of a bird? Follow him forsooth! It will be an evil day for thee\n",
            "when thou seekest to do that.\"\n",
            "****************************************************************************************************\n",
            "The record number : 3386\n",
            "Generated:  Why did the little ones draw back their beaks into a nest?\n",
            "Original :  why did the little ones draw their beaks into the nest?\n",
            "\n",
            "Answer:  they were afraid\n",
            "Conext:  \"Only listen,\" said the young storks, \"to what the boys are singing. Do you hear them say we're to be hanged and shot?\"\n",
            "\"Don't listen to what they say; if you don't mind, it won't hurt you,\" said the mother.\n",
            "But the boys went on singing, and pointed mockingly at the sentinel stork. Only one boy, whom they called Peter, said it was a shame to make game of animals, and he would not join in the singing at all.\n",
            "The mother stork tried to comfort her young ones. \"Don't mind them,\" she said; \"see how quiet your father stands on one leg there.\"\n",
            "\"But we are afraid,\" said the little ones, drawing back their beaks into the nest.\n",
            "****************************************************************************************************\n",
            "The record number : 4118\n",
            "Generated:  Where did Setanta cross before morning?\n",
            "Original :  Where did Setanta cross before morning?\n",
            "\n",
            "Answer:  the frontier\n",
            "Conext:  Of his father he saw little. His mind had become impaired, and he was\n",
            "confined in a secluded part of the Dun. But whenever he spoke to Dectera\n",
            "of what was nearest his heart, and his desire to enter the military\n",
            "school at Emain Macha, she laughed, and said that he was not yet old\n",
            "enough to endure that rough life. But secretly she was alarmed, and\n",
            "formed plans to detain him at home altogether. Then Setanta concealed\n",
            "his desire, but enquired narrowly concerning the partings of the roads\n",
            "on the way to Emania.\n",
            "\n",
            "At last, when he was ten years old, selecting a favourable night,\n",
            "Setanta stole away from his father's Dun, and before morning had crossed\n",
            "the frontier. He then lay down to rest and sleep in a wood. After this\n",
            "he set out again, travelling quickly, lest he should be met by any of\n",
            "his father's people. On his back was strapped his little wooden shield,\n",
            "and by his side hung a sword of lath. He had brought his ball and hurle\n",
            "of red-bronze with him, and ran swiftly along the road, driving the ball\n",
            "before him, or throwing up his javelin into the air, and running to meet\n",
            "it ere it fell.\n",
            "\n",
            "In the afternoon of that day Fergus Mac Roy and the King sat together in\n",
            "the part that surrounded the King's palace. A chessboard was between\n",
            "them, and their attention was fixed on the game.\n",
            "****************************************************************************************************\n",
            "The record number : 4844\n",
            "Generated:  Who was the ruler of men?\n",
            "Original :  Who was the ruler of men?\n",
            "\n",
            "Answer:  Fu Hi\n",
            "Conext:  Long before the time of Fu Hi, Dschu Yung, the Magic Welder, was the\n",
            "ruler of men. He discovered the use of fire, and succeeding\n",
            "generations learned from him to cook their food. Hence his descendants\n",
            "were intrusted with the preservation of fire, while he himself was\n",
            "made the Fire-God. He is a personification of the Red Lord, who showed\n",
            "himself at the beginning of the world as one of the Five Ancients. The\n",
            "Fire-God is worshiped as the Lord of the Holy Southern Mountain. In\n",
            "the skies the Fiery Star, the southern quarter of the heavens and the\n",
            "Red Bird belong to his domain. When there is danger of fire the Fiery\n",
            "Star glows with a peculiar radiance. When countless numbers of\n",
            "fire-crows fly into a house, a fire is sure to break out in it.\n",
            "****************************************************************************************************\n",
            "The record number : 2905\n",
            "Generated:  Why did the crab not climb the tree?\n",
            "Original :  What happened because the crab did not have legs for climbing trees?\n",
            "\n",
            "Answer:  He could not reach the persimmons.\n",
            "Conext:  \"How delicious they will be to eat!\" he said to himself.\n",
            "\n",
            "At last, one day, he knew the persimmons must be quite ripe and he wanted very much to taste one. He made several attempts to climb the tree, in the vain hope of reaching one of the beautiful persimmons hanging above him; but he failed each time, for a crab's legs are not made for climbing trees but only for running along the ground and over stones, both of which he can do most cleverly. In his dilemma he thought of his old playmate the monkey, who, he knew, could climb trees better than any one else in the world. He determined to ask the monkey to help him, and set out to find him.\n",
            "****************************************************************************************************\n",
            "The record number : 475\n",
            "Generated:  What did the cat do after she ate?\n",
            "Original :  What did the cat do after she ate?\n",
            "\n",
            "Answer:  jumped out of the window\n",
            "Conext:  Once upon a time there was a man who had a cat, and she ate so very\n",
            "much that he did not want to keep her any longer. So he decided to tie\n",
            "a stone around her neck, and throw her into the river; but before he\n",
            "did so she was to have something to eat just once more. The woman\n",
            "offered her a dish of mush and a little potful of fat. These she\n",
            "swallowed, and then jumped out of the window. There stood the man on\n",
            "the threshing-floor.\n",
            "****************************************************************************************************\n",
            "The record number : 1083\n",
            "Generated:  What did people want to do with the girl?\n",
            "Original :  What did the people want to do with the girl?\n",
            "\n",
            "Answer:  dance with the girl\n",
            "Conext:  Once upon a time there was a girl who was to go to the wood and drive the cattle home; but she did not find the herd, and losing her way instead, came to a great hill. It had gates and doors and she went in. There stood a table covered with all sorts of good things to eat. And there stood a bed as well, and in the bed lay a great snake. The snake said to the girl: \"Sit down, if you choose! Eat, if you choose! Come and lie down in the bed, if you choose! But if you do not choose, then do not do so.\" So the girl did nothing at all. At last the snake said: \"Some people are coming now who want you to dance with them. But do not go along with them.\" Straightway people arrived who wanted to dance with the girl; but she would hear nothing of it.\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_records=np.random.randint(1,6000,100)"
      ],
      "metadata": {
        "id": "9yOZHxCUg5hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "predicited=[]\n",
        "actual =[]\n",
        "for x in random_records:\n",
        "    generated=predictedQA(Model, train_df['answer'][x], train_df['text'][x])\n",
        "    predicited.append(generated)\n",
        "    actual.append(train_df['question'][x])\n",
        "    count+=1\n",
        "    if count==100:\n",
        "        break\n",
        "        print(\"Break encountred\")"
      ],
      "metadata": {
        "id": "E8Jov2A2G_LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import string\n",
        "import re\n",
        "\n",
        "# BLEURT functions\n",
        "def normalize(text):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(text))))\n",
        "\n",
        "def grade_score(df):\n",
        "    nls = []\n",
        "    for curit, (q, gq) in enumerate(zip(df['reference_question'], df['generated_question'])):\n",
        "        if curit == 100:\n",
        "            break\n",
        "        else:\n",
        "            result = bleurt.compute(predictions=[normalize(q)], references=[normalize(gq)])\n",
        "            nls.append(result)\n",
        "    return nls\n",
        "\n",
        "bleurt = evaluate.load('bleurt', 'bleurt-20')"
      ],
      "metadata": {
        "id": "Vx7WRPPyfaKd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e5dffdece28b47149e34c7386a056a27",
            "62b1af498dc44ed0bd20e6567bd8fd15",
            "8a5d068346464dcd971f0f8335699415",
            "398a578558324c4aa43eabed1e342237",
            "560e8c555e804c36ac697fba0a61bb95",
            "46647dede7fc4f24a90c8ad4dc3c9610",
            "dd862f483cd949c1bf5d2162b44b056f",
            "e43df2a0f89c4e96bc5a86c75da2018f",
            "a32e2caf627b4406ab899911cc994eff",
            "83b9408a0f924a1f8ac4dbdf3a0c6e10",
            "4fc828561c7348a2981fc59e05c2fdac",
            "169004dcc4b047eeb24857a1765d3ca7",
            "00c74d5fb3314bcfaa8db57f88103317",
            "e71653c2fcc34707a14b3ebf54032e24",
            "d9c616afab084163b9809eecd3ab3701",
            "1d8f9c63bf4245838eaa036613bfd08a",
            "59815e2d6f254f2fa2086e16a187eb8c",
            "0d67063812f045d4a8a77bf6ce6bb77b",
            "ac8f7552c9d44ad68f598e33097919e5",
            "fab2d30a6f3645639f6a9d815fc2a0c9",
            "fb031d00057d4964a036519299f52a64",
            "d9f38c002e034abbbbd69593b23a51b9"
          ]
        },
        "outputId": "e7925631-25c4-4349-e5d3-623f027b8e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5dffdece28b47149e34c7386a056a27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.14G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "169004dcc4b047eeb24857a1765d3ca7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(list(zip(predicited,actual)),columns=['generated_question','reference_question'])"
      ],
      "metadata": {
        "id": "NXISfw-0gWwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = grade_score(df)"
      ],
      "metadata": {
        "id": "8SWVfJFeg9al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score= np.mean([x['scores'][0] for x in output],axis=0)\n",
        "print(f'The Bluert score for the 100 data points : {score:.2f}')"
      ],
      "metadata": {
        "id": "cogWrU7Yi8Ts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5ededbd-4775-4521-d24a-53980d162200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Bluert score for the 100 data points : 0.60\n"
          ]
        }
      ]
    }
  ]
}